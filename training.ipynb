{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from main import process_vid\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "from main import dense_optical_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# decaying learning rate (might be better, might not)\n",
    "# shuffle data - DONE\n",
    "# instead of returning object, save data to .npy file in Process_vid DONE\n",
    "# downscale images to a lower resolution / size DOne\n",
    "# train function DONE\n",
    "# test funtion DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20399\n"
     ]
    }
   ],
   "source": [
    "# image processing stuff\n",
    "# this tutorial + opencv docs are good help\n",
    "#https://www.tutorialkart.com/opencv/python/opencv-python-resize-image/\n",
    "\n",
    "# returns grayscale image\n",
    "def grayscale(frame):\n",
    "    return cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# downscales image\n",
    "def downscale(img, scale_percent):\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    return cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "# processes video\n",
    "def process_vid(vid_location, labels_location, save_location):\n",
    "    cap = cv2.VideoCapture(vid_location)\n",
    "    labels = open(labels_location, \"r\")\n",
    "    processed = []\n",
    "    \n",
    "    # get first frame for optical flow\n",
    "    ret, first_frame = cap.read()\n",
    "    first_frame = downscale(first_frame, 50)\n",
    "    prev_frame = grayscale(first_frame)\n",
    "    mask = np.zeros_like(first_frame)\n",
    "    mask[..., 1] = 255 \n",
    "    \n",
    "    for i in tqdm(range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))-1)):\n",
    "    #for i in tqdm(range(1000)):\n",
    "        ret, frame = cap.read()\n",
    "        frame = downscale(frame, 50)\n",
    "        gray = grayscale(frame)\n",
    "        rgb = grayscale(dense_optical_flow(prev_frame, gray, mask))\n",
    "        processed.append([np.array(rgb), labels.readline()])\n",
    "        prev_frame = gray\n",
    "    \n",
    "    cap.release()\n",
    "    labels.close()\n",
    "    np.random.shuffle(processed)\n",
    "    np.save(save_location, processed)\n",
    "    \n",
    "\n",
    "# fetches video data \n",
    "def fetch_data(file_location):\n",
    "    return np.load(file_location, allow_pickle=True)\n",
    "\n",
    "#process_vid(\"data/train.mp4\", \"data/train.txt\", \"data/train_data.npy\")\n",
    "train_data = fetch_data(\"data/train_data.npy\")\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on gpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"running on gpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"running on cpu\")\n",
    "\n",
    "class SpeedNet(nn.Module): # does the name make sense?(yes)\n",
    "    def __init__(self):\n",
    "        # init parent\n",
    "        super().__init__()\n",
    "        \n",
    "        # conv layers (?)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 5)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 5)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 5)\n",
    "        self.conv5 = nn.Conv2d(64,128, 5)\n",
    "        \n",
    "        x = torch.randn(240, 320).view(-1, 1, 240 ,320)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        \n",
    "        # Linear Layer # is less linear layer worse or same or better?\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        #self.forward(x)\n",
    "    \n",
    "    def convs(self, x):\n",
    "        # I feel like this is the equivalent of a noob spamming buttons\n",
    "        # in street fighter and blundering into a win(hopefully)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv5(x)), (2,2))\n",
    "        \n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        #print(self._to_linear)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear) # reshape to pass through linear biz\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = SpeedNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20399/20399 [00:00<00:00, 469419.08it/s]\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([i[0] for i in tqdm(train_data)]).view(-1, 240, 320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20399/20399 [00:00<00:00, 807044.29it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "#TODO: add decaying learning rate\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "#X = torch.Tensor([i[0] for i in tqdm(train_data)]).view(-1, 240, 320)\n",
    "\n",
    "y = torch.Tensor([float(i[1]) for i in tqdm(train_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_PERCENT = 0.05\n",
    "val_size = int(len(X)*VAL_PERCENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19380\n",
      "1019\n"
     ]
    }
   ],
   "source": [
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]\n",
    "\n",
    "train_y = train_y.view(-1, 1) # match the shape of the nets output\n",
    "\n",
    "print(len(train_X))\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:39<00:00,  4.92it/s]\n",
      "  0%|          | 0/194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 12.497451782226562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:39<00:00,  4.93it/s]\n",
      "  0%|          | 0/194 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Loss: 9.73651123046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [00:39<00:00,  4.87it/s]\n",
      "  8%|▊         | 80/1019 [00:00<00:01, 798.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2. Loss: 6.721657752990723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1019/1019 [00:01<00:00, 790.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 3\n",
    "\n",
    "def train(net):\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "            batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 240, 320)\n",
    "            batch_y = train_y[i:i+BATCH_SIZE]\n",
    "            \n",
    "            # mov to gpu\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            net.zero_grad()\n",
    "            outputs = net(batch_X)\n",
    "            loss = loss_function(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
    "\n",
    "def average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "# calculate mse\n",
    "def test(net):\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(test_X))):\n",
    "            net_out = net(test_X[i].view(-1, 1, 240, 320).to(device))[0][0]\n",
    "            real = test_y[i]\n",
    "            results.append((real - net_out)**2)\n",
    "    \n",
    "    return int(average(results))\n",
    "\n",
    "def detailed_test(net):\n",
    "    for i in range(len(test_X)):\n",
    "        pred = int(net(test_X[i].view(-1, 1, 240, 320).to(device)))\n",
    "        real = int(test_y[i])\n",
    "        se = (real - pred)**2\n",
    "        print(f\"real {real}. pred {pred}. se {se}\")\n",
    "        print(\"---------------------\")\n",
    "        \n",
    "train(net)\n",
    "print(\"mse\", test(net)) # I think this is right\n",
    "#detailed_test(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this model\n",
    "def save(path):\n",
    "    torch.save(net.state_dict(), path)\n",
    "\n",
    "save(\"models/big_data_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
